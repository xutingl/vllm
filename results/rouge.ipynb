{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.75, recall=0.6666666666666666, fmeasure=0.7058823529411765),\n",
       " 'rougeL': Score(precision=0.625, recall=0.5555555555555556, fmeasure=0.5882352941176471)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "                      'The quick brown dog jumps on the log.')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge(input_file, reference_file):\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    reference_df = pd.read_csv(reference_file)\n",
    "    assert len(input_df) == len(reference_df)\n",
    "    rouge_scores = []\n",
    "    rougeL_scores = []\n",
    "    for i in range(len(input_df)):\n",
    "        input_text = input_df.iloc[i]['generated_text']\n",
    "        reference_text = reference_df.iloc[i]['generated_text']\n",
    "        scores = scorer.score(input_text, reference_text)\n",
    "        rouge_scores.append(scores)\n",
    "        rougeL_scores.append(scores['rougeL'].precision)\n",
    "    \n",
    "    return sum(rougeL_scores) / len(rougeL_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2575397984396287"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rouge('lmsys_10_ee.csv', 'lmsys_10_eeoff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megatron_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
